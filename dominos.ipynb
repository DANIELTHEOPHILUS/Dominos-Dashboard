{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "313c27b9-ef5c-462b-ba1f-51365f83cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.10-Aug-2025__matrix_days.csv\n"
     ]
    }
   ],
   "source": [
    "# weekly_report_matrix_days.py\n",
    "# Output: Details | Mon | Tue | Wed | Thu | Fri | Sat | Sun | Total\n",
    "# Accepts source Thursday as Thu/Thur/Thurs\n",
    "\n",
    "import os, re, glob\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_DIR  = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\"\n",
    "INPUT_FILE = r\"Mill Park Sales Report w.e.10-Aug-2025.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\"\n",
    "\n",
    "ROW_PATTERNS = [\n",
    "    (r\"^sales\\s*exclusive\\s*gst$\",            \"Sales Exclusive GST\"),\n",
    "    (r\"^no\\.?\\s*of\\s*deliver(y|ies|s)$\",      \"No of Deliveries\"),\n",
    "    (r\"^no\\.?\\s*of\\s*pick\\s*ups?$\",           \"No of PickUps\"),\n",
    "    (r\"^single\\s*deliver(y|ies)?\\s*%$\",       \"Single Deliveries %\"),\n",
    "    (r\"^food\\s*%?\\s*actual$|^food%actual$\",   \"Food%Actual\"),\n",
    "    (r\"^food\\s*%?\\s*theo$|^food%theo$\",       \"Food%Theo\"),\n",
    "    (r\"^labou?r\\s*%$|^labour%$\",              \"LABOUR%\"),\n",
    "    (r\"^uber\\s*eats\\s*sales$\",                \"Uber Eats Sales\"),\n",
    "    (r\"^uber\\s*eats\\s*order\\s*count$\",        \"Uber Eats Order Count\"),\n",
    "    (r\"^uber\\s*eats\\s*commission$\",           \"Uber Eats Commission\"),\n",
    "]\n",
    "\n",
    "# Output day headers (what you want in the CSV)\n",
    "OUTPUT_DAYS = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "# Acceptable source variants for each output day\n",
    "DAY_ALIASES = {\n",
    "    \"Mon\": [\"Mon\"],\n",
    "    \"Tue\": [\"Tue\"],\n",
    "    \"Wed\": [\"Wed\"],\n",
    "    \"Thu\": [\"Thu\", \"Thur\", \"Thurs\"],  # <-- handle all Thursday spellings\n",
    "    \"Fri\": [\"Fri\"],\n",
    "    \"Sat\": [\"Sat\"],\n",
    "    \"Sun\": [\"Sun\"],\n",
    "}\n",
    "\n",
    "def _strip(s):\n",
    "    return str(s).strip() if pd.notna(s) else None\n",
    "\n",
    "def _to_num(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = str(x).strip().replace(\"$\",\"\").replace(\",\",\"\")\n",
    "    if s.endswith(\"%\"): s = s[:-1].strip()\n",
    "    if s in (\"\",\"-\"): return None\n",
    "    try: return float(s)\n",
    "    except: \n",
    "        try: return float(int(float(s)))\n",
    "        except: return None\n",
    "\n",
    "def _load_csv(path):\n",
    "    return pd.read_csv(path, header=None, dtype=str)\n",
    "\n",
    "def find_settings(df):\n",
    "    \"\"\"Find the 'Setting' header row/col and confirm day headers to its right.\"\"\"\n",
    "    day_tokens = set(sum(DAY_ALIASES.values(), []))  # all accepted labels\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]):\n",
    "            val = _strip(df.iat[i,j])\n",
    "            if val and val.lower() == \"setting\":\n",
    "                right = [_strip(df.iat[i, j+k]) for k in range(1, 10) if j+k < df.shape[1]]\n",
    "                if any(r in day_tokens for r in right):\n",
    "                    return i, j\n",
    "    raise ValueError(\"Cannot find 'Setting' header with day columns to the right.\")\n",
    "\n",
    "def match_label(raw):\n",
    "    if not raw: return None\n",
    "    norm = re.sub(r\"\\s+\",\" \", raw.lower().strip())\n",
    "    for pat, name in ROW_PATTERNS:\n",
    "        if re.search(pat, norm): \n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def build_matrix(in_path, out_dir):\n",
    "    raw = _load_csv(in_path)\n",
    "    hdr_row, start_col = find_settings(raw)\n",
    "\n",
    "    # Build header index map from the header row\n",
    "    headers, col_idx = [], {}\n",
    "    for k in range(0, raw.shape[1]-start_col):\n",
    "        v = _strip(raw.iat[hdr_row, start_col+k])\n",
    "        if v:\n",
    "            headers.append(v)\n",
    "            col_idx[v] = start_col + k\n",
    "\n",
    "    # Map each OUTPUT day to whichever source column exists (Thu/Thur/Thurs)\n",
    "    src_for_output = {}\n",
    "    for out_day in OUTPUT_DAYS:\n",
    "        found_src = next((alias for alias in DAY_ALIASES[out_day] if alias in headers), None)\n",
    "        if not found_src:\n",
    "            raise ValueError(f\"Missing day column for '{out_day}'. Looked for any of: {DAY_ALIASES[out_day]}\")\n",
    "        src_for_output[out_day] = found_src\n",
    "\n",
    "    # Read rows under Setting (don’t stop at first blank; some sheets have gaps)\n",
    "    records = []\n",
    "    for i in range(hdr_row + 1, raw.shape[0]):\n",
    "        label_raw = _strip(raw.iat[i, start_col])\n",
    "        if not label_raw:\n",
    "            continue\n",
    "        label = match_label(label_raw)\n",
    "        if label:\n",
    "            row = {\"Details\": label}\n",
    "            total = 0.0\n",
    "            for out_day in OUTPUT_DAYS:\n",
    "                src_day = src_for_output[out_day]\n",
    "                val = _to_num(raw.iat[i, col_idx[src_day]])\n",
    "                row[out_day] = val\n",
    "                if val is not None:\n",
    "                    total += val\n",
    "            row[\"Total\"] = round(total, 2)\n",
    "            records.append(row)\n",
    "\n",
    "    df = pd.DataFrame(records).drop_duplicates(subset=[\"Details\"])\n",
    "    df = df[[\"Details\"] + OUTPUT_DAYS + [\"Total\"]]\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(in_path))[0]\n",
    "    out_path = os.path.join(out_dir, f\"{base}__matrix_days.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    return out_path, df\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    in_path = os.path.join(INPUT_DIR, INPUT_FILE)\n",
    "    out_path, df = build_matrix(in_path, OUTPUT_DIR)\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d1d095-b293-4fbb-8287-3a7db27c102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison file saved: C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\two_weeks_long.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for your two weekly cleaned files\n",
    "week1_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.03-Aug-2025__matrix_days.csv\"\n",
    "week2_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.10-Aug-2025__matrix_days.csv\"\n",
    "output_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\two_weeks_long.csv\"\n",
    "\n",
    "# Read CSVs\n",
    "week1 = pd.read_csv(week1_path)\n",
    "week2 = pd.read_csv(week2_path)\n",
    "\n",
    "# Add week labels (change names to match your file)\n",
    "week1[\"Week\"] = \"03-Aug-2025\"\n",
    "week2[\"Week\"] = \"10-Aug-2025\"\n",
    "\n",
    "# Keep the columns you need\n",
    "cols = [\"Details\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\",\"Total\",\"Week\"]\n",
    "week1 = week1[cols]\n",
    "week2 = week2[cols]\n",
    "\n",
    "# Combine\n",
    "combined = pd.concat([week1, week2])\n",
    "\n",
    "# Unpivot into long format (best for Power BI)\n",
    "long_df = combined.melt(\n",
    "    id_vars=[\"Week\",\"Details\"],\n",
    "    value_vars=[\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"],\n",
    "    var_name=\"Day\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Save for Power BI\n",
    "long_df.to_csv(output_path, index=False)\n",
    "print(\"✅ Comparison file saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b9c85d-f176-4e7f-a7bf-c056dd396a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged file: C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\weekly_comparison.csv\n",
      "                  Details  Day    Value             Week  DaySort\n",
      "0     Sales Exclusive GST  Mon  2605.96  W/E 03-aug-2025        1\n",
      "1        No of Deliveries  Mon    38.00  W/E 03-aug-2025        1\n",
      "2           No of PickUps  Mon    57.00  W/E 03-aug-2025        1\n",
      "3     Single Deliveries %  Mon    68.00  W/E 03-aug-2025        1\n",
      "4             Food%Actual  Mon    27.40  W/E 03-aug-2025        1\n",
      "5               Food%Theo  Mon    29.59  W/E 03-aug-2025        1\n",
      "6                 LABOUR%  Mon    35.44  W/E 03-aug-2025        1\n",
      "7         Uber Eats Sales  Mon   641.00  W/E 03-aug-2025        1\n",
      "8   Uber Eats Order Count  Mon    15.00  W/E 03-aug-2025        1\n",
      "9    Uber Eats Commission  Mon    98.71  W/E 03-aug-2025        1\n",
      "10    Sales Exclusive GST  Tue  3336.17  W/E 03-aug-2025        2\n",
      "11       No of Deliveries  Tue    42.00  W/E 03-aug-2025        2\n",
      "12          No of PickUps  Tue   114.00  W/E 03-aug-2025        2\n",
      "13    Single Deliveries %  Tue    81.00  W/E 03-aug-2025        2\n",
      "14            Food%Actual  Tue    32.08  W/E 03-aug-2025        2\n"
     ]
    }
   ],
   "source": [
    "# weekly_merge_unpivot.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Input Files (replace with your actual file paths) ===\n",
    "file1 = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.03-Aug-2025__matrix_days.csv\"\n",
    "file2 = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.10-Aug-2025__matrix_days.csv\"\n",
    "\n",
    "# === Output File ===\n",
    "out_file = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\weekly_comparison.csv\"\n",
    "\n",
    "# --- Function to load and reshape a single file ---\n",
    "def load_weekly_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Extract week ending from filename\n",
    "    base = os.path.basename(path)\n",
    "    if \"w.e.\" in base.lower():\n",
    "        week = base.lower().split(\"w.e.\")[-1].replace(\"__matrix_days.csv\",\"\").strip()\n",
    "    else:\n",
    "        week = base\n",
    "\n",
    "    # Standardize Thursday column\n",
    "    df = df.rename(columns=lambda c: c.replace(\"Thur\",\"Thu\").replace(\"Thurs\",\"Thu\"))\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    days = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    keep_cols = [\"Details\"] + [d for d in days if d in df.columns]\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Unpivot Mon–Sun\n",
    "    df = df.melt(id_vars=\"Details\", value_vars=days, var_name=\"Day\", value_name=\"Value\")\n",
    "\n",
    "    # Add Week column\n",
    "    df[\"Week\"] = \"W/E \" + week\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Load both weeks ---\n",
    "df1 = load_weekly_csv(file1)\n",
    "df2 = load_weekly_csv(file2)\n",
    "\n",
    "# --- Combine ---\n",
    "merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# --- Drop rows with missing values ---\n",
    "merged = merged.dropna(subset=[\"Value\"])\n",
    "\n",
    "# --- Convert to numeric ---\n",
    "merged[\"Value\"] = pd.to_numeric(merged[\"Value\"], errors=\"coerce\")\n",
    "\n",
    "# --- Add DaySort for ordering ---\n",
    "day_order = {\"Mon\":1,\"Tue\":2,\"Wed\":3,\"Thu\":4,\"Fri\":5,\"Sat\":6,\"Sun\":7}\n",
    "merged[\"DaySort\"] = merged[\"Day\"].map(day_order)\n",
    "\n",
    "# --- Save output ---\n",
    "merged.to_csv(out_file, index=False)\n",
    "\n",
    "print(f\"Saved merged file: {out_file}\")\n",
    "print(merged.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9cfb18c-819a-4aac-bd9c-9ef9220dcd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved merged file: C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\weekly_comparison.csv\n",
      "                  Details  Day    Value             Week\n",
      "0     Sales Exclusive GST  Mon  2605.96  W/E 03-aug-2025\n",
      "1        No of Deliveries  Mon    38.00  W/E 03-aug-2025\n",
      "2           No of PickUps  Mon    57.00  W/E 03-aug-2025\n",
      "3     Single Deliveries %  Mon    68.00  W/E 03-aug-2025\n",
      "4             Food%Actual  Mon    27.40  W/E 03-aug-2025\n",
      "5               Food%Theo  Mon    29.59  W/E 03-aug-2025\n",
      "6                 LABOUR%  Mon    35.44  W/E 03-aug-2025\n",
      "7         Uber Eats Sales  Mon   641.00  W/E 03-aug-2025\n",
      "8   Uber Eats Order Count  Mon    15.00  W/E 03-aug-2025\n",
      "9    Uber Eats Commission  Mon    98.71  W/E 03-aug-2025\n",
      "10    Sales Exclusive GST  Tue  3336.17  W/E 03-aug-2025\n",
      "11       No of Deliveries  Tue    42.00  W/E 03-aug-2025\n"
     ]
    }
   ],
   "source": [
    "# weekly_merge_unpivot.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Input Files (replace with your actual file paths) ===\n",
    "file1 = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.03-Aug-2025__matrix_days.csv\"\n",
    "file2 = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\Mill Park Sales Report w.e.10-Aug-2025__matrix_days.csv\"\n",
    "\n",
    "# === Output File ===\n",
    "out_file = r\"C:\\Users\\user\\OneDrive\\Desktop\\Dominos\\Clean\\weekly_comparison.csv\"\n",
    "\n",
    "def load_weekly_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Extract week ending from filename\n",
    "    base = os.path.basename(path)\n",
    "    if \"w.e.\" in base.lower():\n",
    "        week = base.lower().split(\"w.e.\")[-1].replace(\"__matrix_days.csv\",\"\").strip()\n",
    "    else:\n",
    "        week = base\n",
    "\n",
    "    # Standardize Thursday column names\n",
    "    df = df.rename(columns=lambda c: c.replace(\"Thur\",\"Thu\").replace(\"Thurs\",\"Thu\"))\n",
    "\n",
    "    # Keep only Mon–Sun + Details\n",
    "    days = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    keep_cols = [\"Details\"] + [d for d in days if d in df.columns]\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Unpivot into long format\n",
    "    df = df.melt(id_vars=\"Details\", value_vars=days, var_name=\"Day\", value_name=\"Value\")\n",
    "\n",
    "    # Add Week column\n",
    "    df[\"Week\"] = \"W/E \" + week\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load both weeks\n",
    "df1 = load_weekly_csv(file1)\n",
    "df2 = load_weekly_csv(file2)\n",
    "\n",
    "# Merge\n",
    "merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Drop blanks\n",
    "merged = merged.dropna(subset=[\"Value\"])\n",
    "merged[\"Value\"] = pd.to_numeric(merged[\"Value\"], errors=\"coerce\")\n",
    "\n",
    "# Save\n",
    "merged.to_csv(out_file, index=False)\n",
    "\n",
    "print(f\"✅ Saved merged file: {out_file}\")\n",
    "print(merged.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ce32f-3a9d-422d-8d19-1979294e0d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
